[2025-04-15T19:27:23.548+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-15T19:27:23.636+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: lab1StockETL.extract scheduled__2025-04-14T02:30:00+00:00 [queued]>
[2025-04-15T19:27:23.665+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: lab1StockETL.extract scheduled__2025-04-14T02:30:00+00:00 [queued]>
[2025-04-15T19:27:23.669+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-04-15T19:27:23.708+0000] {taskinstance.py:2888} INFO - Executing <Task(_PythonDecoratedOperator): extract> on 2025-04-14 02:30:00+00:00
[2025-04-15T19:27:23.790+0000] {logging_mixin.py:190} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70 DeprecationWarning: This process (pid=1913) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-04-15T19:27:23.789+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'lab1StockETL', 'extract', 'scheduled__2025-04-14T02:30:00+00:00', '--job-id', '153', '--raw', '--subdir', 'DAGS_FOLDER/lab1_ETL.py', '--cfg-path', '/tmp/tmptj36kim6']
[2025-04-15T19:27:23.793+0000] {standard_task_runner.py:105} INFO - Job 153: Subtask extract
[2025-04-15T19:27:23.793+0000] {standard_task_runner.py:72} INFO - Started process 1921 to run task
[2025-04-15T19:27:23.955+0000] {task_command.py:467} INFO - Running <TaskInstance: lab1StockETL.extract scheduled__2025-04-14T02:30:00+00:00 [running]> on host e3cb891c5fca
[2025-04-15T19:27:24.257+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='lab1StockETL' AIRFLOW_CTX_TASK_ID='extract' AIRFLOW_CTX_EXECUTION_DATE='2025-04-14T02:30:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-14T02:30:00+00:00'
[2025-04-15T19:27:24.261+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-04-15T19:27:24.268+0000] {logging_mixin.py:190} INFO - YF.download() has changed argument auto_adjust default to True
[2025-04-15T19:27:25.883+0000] {logging_mixin.py:190} WARNING - [*********************100%***********************]  1 of 1 completed
[2025-04-15T19:27:26.285+0000] {logging_mixin.py:190} WARNING - [*********************100%***********************]  1 of 1 completed
[2025-04-15T19:27:26.291+0000] {python.py:240} INFO - Done. Returned value was: {'NVDA': Price            Close        High         Low        Open     Volume
Ticker            NVDA        NVDA        NVDA        NVDA       NVDA
Date                                                                 
2024-07-29  111.562500  116.251347  111.272578  113.661989  248152100
2024-07-30  103.704445  111.962404  102.514736  111.492519  486833300
2024-07-31  116.991158  118.310832  110.852671  112.872178  473174200
2024-08-01  109.183098  120.130405  106.783687  117.501048  523462300
2024-08-02  107.243561  108.693208  101.345021  103.734431  482027500
...                ...         ...         ...         ...        ...
2025-04-09  114.330002  115.099998   97.529999   98.889999  612918300
2025-04-10  107.570000  110.860001   99.150002  109.370003  437812400
2025-04-11  110.930000  111.550003  107.480003  108.500000  313417300
2025-04-14  110.709999  114.290001  109.070000  114.110001  263685000
2025-04-15  112.088303  113.614998  110.500000  110.970001  180111417

[180 rows x 5 columns], 'AAPL': Price            Close        High         Low        Open     Volume
Ticker            AAPL        AAPL        AAPL        AAPL       AAPL
Date                                                                 
2024-07-29  217.508972  218.565419  215.027307  216.233261   36311800
2024-07-30  218.067093  219.591967  215.396062  218.455786   41643800
2024-07-31  221.336105  223.070282  219.890965  220.698250   50036300
2024-08-01  217.628571  223.728066  216.293063  223.618434   62501000
2024-08-02  219.123550  224.844329  216.980758  218.415922  105568600
...                ...         ...         ...         ...        ...
2025-04-09  198.850006  200.610001  171.889999  171.949997  184395900
2025-04-10  190.419998  194.779999  183.000000  189.070007  121880000
2025-04-11  198.149994  199.539993  186.059998  186.100006   87435900
2025-04-14  202.520004  212.940002  201.160004  211.440002  101203700
2025-04-15  202.660004  203.505005  199.820007  201.854996   35092271

[180 rows x 5 columns]}
[2025-04-15T19:27:27.081+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-04-15T19:27:27.087+0000] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=lab1StockETL, task_id=extract, run_id=scheduled__2025-04-14T02:30:00+00:00, execution_date=20250414T023000, start_date=20250415T192723, end_date=20250415T192727
[2025-04-15T19:27:27.224+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-15T19:27:27.326+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2664, in partial_subset
    t.task_id: _deepcopy_task(t)
               ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 143, in deepcopy
    y = copier(memo)
        ^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
                       ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 201, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
         ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 162, in deepcopy
    y = _reconstruct(x, memo, *rv)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 259, in _reconstruct
    state = deepcopy(state, memo)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 136, in deepcopy
    y = copier(x, memo)
        ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 221, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
                             ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/copy.py", line 151, in deepcopy
    rv = reductor(4)
         ^^^^^^^^^^^
TypeError: cannot pickle '_thread.lock' object
[2025-04-15T19:27:27.342+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
